<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>模式识别导论：第5章 Support Vector Machines - harry-zzh的博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="harry-zzh的博客"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="harry-zzh的博客"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="本章介绍支持向量机（SVM）的相关知识，介绍了基本概念，以及SVM的三种种类：硬间隔、软间隔、非线性（基于核函数）。最后总结了SVM的优缺点。"><meta property="og:type" content="blog"><meta property="og:title" content="模式识别导论：第5章 Support Vector Machines"><meta property="og:url" content="http://harry-zzh.github.io/2021/05/14/PR-ch5/"><meta property="og:site_name" content="harry-zzh的博客"><meta property="og:description" content="本章介绍支持向量机（SVM）的相关知识，介绍了基本概念，以及SVM的三种种类：硬间隔、软间隔、非线性（基于核函数）。最后总结了SVM的优缺点。"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://harry-zzh.github.io/2021/05/14/PR-ch5/%E6%A0%B8%E5%87%BD%E6%95%B0.PNG"><meta property="og:image" content="http://harry-zzh.github.io/2021/05/14/PR-ch5/%E6%A0%B8%E7%9A%84%E5%88%A4%E6%96%AD.PNG"><meta property="article:published_time" content="2021-05-14T06:26:22.000Z"><meta property="article:modified_time" content="2021-06-10T07:55:13.945Z"><meta property="article:author" content="harry-zzh"><meta property="article:tag" content="模式识别"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2021/05/14/PR-ch5/%E6%A0%B8%E5%87%BD%E6%95%B0.PNG"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://harry-zzh.github.io/2021/05/14/PR-ch5/"},"headline":"模式识别导论：第5章 Support Vector Machines","image":[],"datePublished":"2021-05-14T06:26:22.000Z","dateModified":"2021-06-10T07:55:13.945Z","author":{"@type":"Person","name":"harry-zzh"},"description":"本章介绍支持向量机（SVM）的相关知识，介绍了基本概念，以及SVM的三种种类：硬间隔、软间隔、非线性（基于核函数）。最后总结了SVM的优缺点。"}</script><link rel="canonical" href="http://harry-zzh.github.io/2021/05/14/PR-ch5/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.svg" alt="harry-zzh的博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Harry-zzh"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>模式识别导论：第5章 Support Vector Machines</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2021-05-14</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2021-06-10</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%A1%E7%A7%91/">计科</a></span><span class="level-item">13 minutes read (About 1897 words)</span></div></div><div class="content"><p>本章介绍支持向量机（SVM）的相关知识，介绍了基本概念，以及SVM的三种种类：硬间隔、软间隔、非线性（基于核函数）。最后总结了SVM的优缺点。<br><span id="more"></span></p>
<h1 id="1-Classification-Margin"><a href="#1-Classification-Margin" class="headerlink" title="1. Classification Margin"></a>1. Classification Margin</h1><ul>
<li>support vectors（支持向量）：<strong>离超平面最近的数据点</strong>。</li>
<li>margin（边距）：定义为支持向量的距离。</li>
<li>优化目标是<strong>尽可能最大化margin</strong>，这也是SVM的目标。由于只和support vectors有关，减轻过拟合并最小化了复杂程度。</li>
</ul>
<h1 id="2-Support-Vector-Machines-for-Classification"><a href="#2-Support-Vector-Machines-for-Classification" class="headerlink" title="2. Support Vector Machines for Classification"></a>2. Support Vector Machines for Classification</h1><h2 id="2-1-Linear-Discrimination"><a href="#2-1-Linear-Discrimination" class="headerlink" title="2.1 Linear Discrimination"></a>2.1 Linear Discrimination</h2><h3 id="2-1-1-硬间隔SVM"><a href="#2-1-1-硬间隔SVM" class="headerlink" title="2.1.1 硬间隔SVM"></a>2.1.1 硬间隔SVM</h3><ul>
<li>任一数据点 x 到超平面的距离：$r=\frac{w^Tx+b}{||w||}$（r的符号由分子的符号有关）<ul>
<li>推导：<ul>
<li>设有向量$x_0$，方向是超平面的方向。利用向量减法，得到$x-x_0=\frac{rw}{||w||}$，即$x_0=x-\frac{rw}{||w||}$。将$w^Tx_0+b=0$代入，得到$w^Tx-\frac{rw^Tw}{||w||}+b=0$。</li>
<li>由于$\sqrt{w^Tw}=||w||$，则上式可化为：$r=\frac{w^Tx+b}{||w||}$。</li>
</ul>
</li>
</ul>
</li>
<li><p>假设支持向量到超平面的距离为$d (d &gt;0)$，则：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  y_i &= +1:\frac{w^Tx_i+b}{||w||}\geq d \\
  y_i &= -1:\frac{w^Tx_i+b}{||w||}\leq -d 
  \end{aligned}</script><p>  可以假设$||w||d=1$，不影响后续优化问题的解决：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  y_i &= +1:w^Tx_i+b\geq 1 \\
  y_i &= -1:w^Tx_i+b\leq -1
  \end{aligned}</script></li>
<li>优化目标是最大化margin，而支持向量到平面的距离为$w^Tx_i+b=1$和$w^Tx_i+b=-1$，则margin = $\frac{2}{||w||}$。</li>
<li>转换为Quadratic optimization problem（二次规划）问题：<strong>最小化</strong> $\frac{1}{2}||w||^2$，<strong>约束条件</strong>是$y_i(w^Tx_i+b)\geq1$。这被称为<strong>带约束的原始问题</strong>。</li>
<li><p><strong>拉格朗日函数</strong>：$L(w,b,\alpha)=\frac{1}{2}||w||^2+\sum\alpha_i(1-y_i(w^Tx_i+b))$。即<strong>无约束的原始问题</strong>，优化目标：$min_{w,b}max_{\alpha}L(w,b,\alpha)$</p>
<ul>
<li>该问题的<strong>对偶问题</strong>（dual problem）：$max_{\alpha}min_{w,b}L(w,b,\alpha)$。因为有<strong>弱对偶关系</strong>$min_{w,b}max_{\alpha}L(w,b,\alpha)\geq max_{\alpha}min_{w,b}L(w,b,\alpha)$，而原始问题是凸二次优化问题，存在强对偶关系，该式可取等号。</li>
<li><p>对$w,b$求偏导，令$\frac{\partial L}{\partial w}=\frac{\partial L}{\partial b}=0$：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  &w=\sum \alpha_ix_iy_i\\
  &\sum\alpha_iy_i=0
  \end{aligned}</script><p>  注意，这里涉及到了<strong>标量对向量的求导</strong>：$\frac{\partial (\frac{1}{2}||w||^2)}{\partial w}$，求导的结果也是个<strong>向量</strong>。因为$\frac{1}{2}||w||^2=\frac{1}{2}\sum w_i^2$，对第k个分量求导得$\frac{\partial (\frac{1}{2}||w||^2)}{\partial w_k}=w_k$，所以，$\frac{\partial (\frac{1}{2}||w||^2)}{\partial w}=w$。</p>
<p>  $x_i$是向量，$y_i,b$都是标量。</p>
</li>
<li><p>将上述式子代入$L(w,b,\alpha)$，得到：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  L(w,b,\alpha)&=\frac{1}{2}w^Tw+\sum\alpha_i-\sum\alpha_iy_iw^Tx_i-0\\
  &=\frac{1}{2}(\sum_{i=1} \alpha_ix_iy_i)^T(\sum_{i=1} \alpha_ix_iy_i)+\sum_{i=1}\alpha_i-\sum_{i=1}\alpha_iy_i(\sum_{i=1} \alpha_ix_iy_i)^Tx_i\\
  &=\frac{1}{2}(\sum_{i=1} \sum_{j=1}\alpha_i\alpha_jy_iy_jx_i^Tx_j)+\sum_{i=1}\alpha_i-\sum_{i=1} \sum_{j=1}\alpha_i\alpha_jy_iy_jx_i^Tx_j \\
  &=\sum_{i=1}\alpha_i-\frac{1}{2}(\sum_{i=1} \sum_{j=1}\alpha_i\alpha_jy_iy_jx_i^Tx_j)
  \end{aligned}</script><p>  注意，第二步到第三步将两个求和公式合并时，引入了$j$，可以类比简单的乘法$(1+2) \times (1+2)=1 \times (1+2) + 2 \times (1+2)=\sum_{i=1}^2i\sum_{j=1}^2j$，就能理解为什么引入$j$了。</p>
</li>
<li><strong>故对偶问题转换为</strong>：$max_{\alpha}(\sum_{i=1}\alpha_i-\frac{1}{2}\sum_{i=1} \sum_{j=1}\alpha_i\alpha_jy_iy_jx_i^Tx_j)$，且$\alpha_i\geq 0,\sum\alpha_iy_i=0$。可以用通用的二次规划解法来求解$\alpha$，但是<strong>问题的规模正比于训练样本数，开销较大</strong>。可以选择一些高效的算法，比如<strong>SMO算法</strong>来求解$\alpha$，这里不展开讲。</li>
<li>得到$\alpha$后，即得$f(x)=w^Tx + b =\sum \alpha_iy_ix_i^Tx+b$。</li>
<li><p>注意到带约束的原始问题有不等式约束，需满足<strong>KKT条件</strong>：</p>
<script type="math/tex; mode=display">
  \begin{cases}
  \alpha_i\geq 0\\
  y_if(x_i)-1\geq 0\\
  \alpha_i(y_if(x_i)-1)=0
  \end{cases}</script><p>  分别称为乘子条件、约束条件、互补条件。</p>
<p>  易得<strong>非支持向量</strong>对于$f(x)$无影响，因为$y_if(x_i)-1\neq 0$，为满足$\alpha_i(y_if(x_i)-1)=0$，则$\alpha_i=0$。因此，<strong>最终模型仅与支持向量有关</strong>，即$f(x)=\sum_{i\in S} \alpha_iy_ix_i^Tx+b$。</p>
</li>
<li><p>所以，$w,b$的计算<strong>可简化</strong>为：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  w&=\sum_{i\in S} \alpha_ix_iy_i \\
  b&=1/y_s- \sum_{i\in S}\alpha_iy_ix_i^Tx_s
  \end{aligned}</script><p>  S是支持向量的集合，b是根据f(x)的公式得到的。$x_s$是某一支持向量。</p>
<p>  虽然可选用任一支持向量得到b，但是常采用更鲁棒的做法：<strong>使用所有支持向量求解的平均值</strong>：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  b&=1/|S|\sum_{s\in S}(1/y_s- \sum_{i\in S}\alpha_iy_ix_i^Tx_s)\\
  &=1/|S|\sum_{s\in S}(y_s- \sum_{i\in S}\alpha_iy_ix_i^Tx_s)
  \end{aligned}</script><p>  （因为$1/y_s$要么是1，要么是-1，可简化）</p>
</li>
</ul>
</li>
</ul>
<h3 id="2-1-2-软间隔SVM"><a href="#2-1-2-软间隔SVM" class="headerlink" title="2.1.2 软间隔SVM"></a>2.1.2 软间隔SVM</h3><ul>
<li>有时候数据并不是线性可分的，解决这一问题的方法之一是引入<strong>软间隔</strong>的概念，即允许有些数据点不满足$y_i(w^Tx_i+b)\geq1$的约束条件。</li>
<li>设<strong>slack variable（松弛变量）</strong>为$\epsilon_i$，则<strong>带约束的原始问题为：最小化</strong> $\frac{1}{2}||w||^2+C\sum\epsilon_i$，约束条件是$y_i(w^Tx_i+b)\geq1-\epsilon_i$，且$\epsilon_i\geq0$。参数$C&gt;0$被称作<strong>惩罚参数</strong>。$C$越大对误分类惩罚越大，取正无穷就是<strong>硬间隔SVM</strong>，越小对误分类惩罚越小。<strong>$C$过大容易过拟合，过小容易欠拟合</strong>。</li>
<li>可以用和求解硬间隔SVM的相同方法求解参数。</li>
</ul>
<h2 id="2-2-Nonlinear-Discrimination"><a href="#2-2-Nonlinear-Discrimination" class="headerlink" title="2.2 Nonlinear Discrimination"></a>2.2 Nonlinear Discrimination</h2><ul>
<li>在原始样本空间内可能找不到能划分两类样本的超平面，可以将样本映射到更高维的特征空间，在这个空间内进行线性分类。</li>
<li>设$\phi(x)$是样本映射后的特征向量，则超平面的表达式：$f(x)=\sum_{i\in S} \alpha_iy_i\phi(x_i)^T\phi(x)+b$。</li>
<li>由于特征空间的维数可能很高，直接计算内积很困难，因此引入<strong>核函数</strong>：$k(x_i,x_j)=\phi(x_i)^T\phi(x_j)$，即$x_i,x_j$<strong>在特征空间的内积等于在原始样本空间内通过核函数计算的结果，这也被称作核技巧（kernel trick）</strong>。</li>
<li>模型改写为：$f(x)=\sum_{i\in S} \alpha_iy_ik(x,x_i)+b$。</li>
<li><strong>Mercer’s theorem：任意一个对称函数所对应的核矩阵半正定，则其能作为核函数。</strong></li>
<li>常用的核函数：  <div style="width:60%;margin:auto">
  <img src="/2021/05/14/PR-ch5/%E6%A0%B8%E5%87%BD%E6%95%B0.PNG" class title="核函数">
  </div></li>
<li>核函数可以通过组合得到：  <div style="width:60%;margin:auto">
  <img src="/2021/05/14/PR-ch5/%E6%A0%B8%E7%9A%84%E5%88%A4%E6%96%AD.PNG" class title="核的判断">
  </div>

</li>
</ul>
<h1 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3. Summary"></a>3. Summary</h1><ul>
<li>优点<ul>
<li><strong>Good generalization</strong> in theory and in practice</li>
<li>Work well with <strong>few training instances</strong></li>
<li>Find <strong>globally</strong> best model</li>
<li><strong>Efficient</strong> algorithms</li>
<li>Amenable to the <strong>kernel trick</strong></li>
</ul>
</li>
<li>缺点<ul>
<li>二次规划问题求解时的运算规模较大，不适用于超大数据集（SMO算法可以缓解这个问题）。</li>
<li>只适用于二分类问题。（SVM的推广SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题）</li>
</ul>
</li>
</ul>
<h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4. 参考资料"></a>4. 参考资料</h1><ul>
<li>周志华《机器学习》</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49331510">https://zhuanlan.zhihu.com/p/49331510</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>模式识别导论：第5章 Support Vector Machines</p><p><a href="http://harry-zzh.github.io/2021/05/14/PR-ch5/">http://harry-zzh.github.io/2021/05/14/PR-ch5/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>harry-zzh</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-05-14</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-06-10</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/">模式识别 </a></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/05/18/PR-ch6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">模式识别导论：第6章 Decision Trees</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/05/13/NA-ch7/"><span class="level-item">数值分析：第7章 非线性方程和非线性方程组的数值解</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="harry-zzh"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">harry-zzh</p><p class="is-size-6 is-block">华南理工大学 计科</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>广东 广州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">7</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Harry-zzh" target="_blank" rel="noopener">Follow</a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#1-Classification-Margin"><span class="level-left"><span class="level-item">1. Classification Margin</span></span></a></li><li><a class="level is-mobile" href="#2-Support-Vector-Machines-for-Classification"><span class="level-left"><span class="level-item">2. Support Vector Machines for Classification</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#2-1-Linear-Discrimination"><span class="level-left"><span class="level-item">2.1 Linear Discrimination</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#2-1-1-硬间隔SVM"><span class="level-left"><span class="level-item">2.1.1 硬间隔SVM</span></span></a></li><li><a class="level is-mobile" href="#2-1-2-软间隔SVM"><span class="level-left"><span class="level-item">2.1.2 软间隔SVM</span></span></a></li></ul></li><li><a class="level is-mobile" href="#2-2-Nonlinear-Discrimination"><span class="level-left"><span class="level-item">2.2 Nonlinear Discrimination</span></span></a></li></ul></li><li><a class="level is-mobile" href="#3-Summary"><span class="level-left"><span class="level-item">3. Summary</span></span></a></li><li><a class="level is-mobile" href="#4-参考资料"><span class="level-left"><span class="level-item">4. 参考资料</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.svg" alt="harry-zzh的博客" height="28"></a><p class="is-size-7"><span>&copy; 2021 harry-zzh</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Harry-zzh"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>